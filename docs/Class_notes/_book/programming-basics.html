<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Notes for Statistical Computing &amp; Machine Learning</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Notes and other materials for Math 253 at Macalester College.">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Notes for Statistical Computing &amp; Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notes and other materials for Math 253 at Macalester College." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Notes for Statistical Computing &amp; Machine Learning" />
  
  <meta name="twitter:description" content="Notes and other materials for Math 253 at Macalester College." />
  

<meta name="author" content="Daniel Kaplan">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="support-vector-classifiers.html">
<link rel="next" href="appendices.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math 253 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#math-253-and-the-macalester-statistics-curriculum"><i class="fa fa-check"></i>Math 253 and the Macalester statistics curriculum</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#these-notes-are-written-in-bookdown"><i class="fa fa-check"></i>These notes are written in Bookdown</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#statistical-and-machine-learning"><i class="fa fa-check"></i><b>1.1</b> Statistical and Machine Learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introduction.html"><a href="introduction.html#example-1-machine-translation-of-natural-languages"><i class="fa fa-check"></i><b>1.1.1</b> Example 1: Machine translation of natural languages</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction.html"><a href="introduction.html#example-2-from-library-catalogs-to-latent-semantic-indexing"><i class="fa fa-check"></i><b>1.1.2</b> Example 2: From library catalogs to latent semantic indexing</a></li>
<li class="chapter" data-level="1.1.3" data-path="introduction.html"><a href="introduction.html#computing-technique"><i class="fa fa-check"></i><b>1.1.3</b> Computing technique</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#review-of-day-1"><i class="fa fa-check"></i><b>1.2</b> Review of Day 1</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#theoretical-concepts-isl-2.1"><i class="fa fa-check"></i><b>1.3</b> Theoretical concepts ISL §2.1</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#statistics-concepts"><i class="fa fa-check"></i><b>1.3.1</b> Statistics concepts</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#computing-concepts"><i class="fa fa-check"></i><b>1.3.2</b> Computing concepts</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#cross-fertilization"><i class="fa fa-check"></i><b>1.3.3</b> Cross fertilization</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#many-techniques"><i class="fa fa-check"></i><b>1.4</b> Many techniques</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.4.1</b> Unsupervised learning</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#supervised-learning"><i class="fa fa-check"></i><b>1.4.2</b> Supervised learning:</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#basic-dicotomies-in-machine-learning"><i class="fa fa-check"></i><b>1.5</b> Basic dicotomies in machine learning</a><ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#purposes-for-learning"><i class="fa fa-check"></i><b>1.5.1</b> Purposes for learning:</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction.html"><a href="introduction.html#dicotomies"><i class="fa fa-check"></i><b>1.5.2</b> Dicotomies</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction.html"><a href="introduction.html#prediction-versus-mechanism"><i class="fa fa-check"></i><b>1.5.3</b> Prediction versus mechanism</a></li>
<li class="chapter" data-level="1.5.4" data-path="introduction.html"><a href="introduction.html#flexibility-versus-variance"><i class="fa fa-check"></i><b>1.5.4</b> Flexibility versus variance</a></li>
<li class="chapter" data-level="1.5.5" data-path="introduction.html"><a href="introduction.html#black-box-vs-interpretable-models"><i class="fa fa-check"></i><b>1.5.5</b> Black box vs interpretable models</a></li>
<li class="chapter" data-level="1.5.6" data-path="introduction.html"><a href="introduction.html#reducible-versus-irreducible-error"><i class="fa fa-check"></i><b>1.5.6</b> Reducible versus irreducible error</a></li>
<li class="chapter" data-level="1.5.7" data-path="introduction.html"><a href="introduction.html#regression-versus-classification"><i class="fa fa-check"></i><b>1.5.7</b> Regression versus classification</a></li>
<li class="chapter" data-level="1.5.8" data-path="introduction.html"><a href="introduction.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>1.5.8</b> Supervised versus unsupervised</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#programming-activity-1"><i class="fa fa-check"></i><b>1.6</b> Programming Activity 1</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#review-of-day-2"><i class="fa fa-check"></i><b>1.7</b> Review of Day 2</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introduction.html"><a href="introduction.html#trade-offsdicotomies"><i class="fa fa-check"></i><b>1.7.1</b> Trade-offs/Dicotomies</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#a-classifier-example"><i class="fa fa-check"></i><b>1.8</b> A Classifier example</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#programming-activity-2"><i class="fa fa-check"></i><b>1.9</b> Programming Activity 2</a></li>
<li class="chapter" data-level="1.10" data-path="introduction.html"><a href="introduction.html#day-3-theory-accuracy-precision-and-bias"><i class="fa fa-check"></i><b>1.10</b> Day 3 theory: accuracy, precision, and bias</a><ul>
<li class="chapter" data-level="1.10.1" data-path="introduction.html"><a href="introduction.html#figure-2.10"><i class="fa fa-check"></i><b>1.10.1</b> Figure 2.10</a></li>
<li class="chapter" data-level="1.10.2" data-path="introduction.html"><a href="introduction.html#another-example-a-smoother-simulated-fx."><i class="fa fa-check"></i><b>1.10.2</b> Another example: A smoother simulated <span class="math inline">\(f(x)\)</span>.</a></li>
<li class="chapter" data-level="1.10.3" data-path="introduction.html"><a href="introduction.html#whats-the-best-of-these-models"><i class="fa fa-check"></i><b>1.10.3</b> What’s the “best” of these models?</a></li>
<li class="chapter" data-level="1.10.4" data-path="introduction.html"><a href="introduction.html#why-is-testing-mse-u-shaped"><i class="fa fa-check"></i><b>1.10.4</b> Why is testing MSE U-shaped?</a></li>
<li class="chapter" data-level="1.10.5" data-path="introduction.html"><a href="introduction.html#measuring-the-variance-of-independent-sources-of-variation"><i class="fa fa-check"></i><b>1.10.5</b> Measuring the variance of independent sources of variation</a></li>
<li class="chapter" data-level="1.10.6" data-path="introduction.html"><a href="introduction.html#equation-2.7"><i class="fa fa-check"></i><b>1.10.6</b> Equation 2.7</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="introduction.html"><a href="introduction.html#programming-activity-3"><i class="fa fa-check"></i><b>1.11</b> Programming Activity 3</a></li>
<li class="chapter" data-level="1.12" data-path="introduction.html"><a href="introduction.html#review-of-day-3"><i class="fa fa-check"></i><b>1.12</b> Review of Day 3</a></li>
<li class="chapter" data-level="1.13" data-path="introduction.html"><a href="introduction.html#start-thursday-15-sept."><i class="fa fa-check"></i><b>1.13</b> Start Thursday 15 Sept.</a></li>
</ul></li>
<li class="part"><span><b>I Topic I: Linear Regression</b></span><ul>
<li class="chapter" data-level="1.14" data-path="introduction.html"><a href="introduction.html#day-4-preview"><i class="fa fa-check"></i><b>1.14</b> Day 4 Preview</a></li>
<li class="chapter" data-level="1.15" data-path="introduction.html"><a href="introduction.html#small-data"><i class="fa fa-check"></i><b>1.15</b> Small data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>2</b> Notes</a><ul>
<li class="chapter" data-level="2.1" data-path="notes.html"><a href="notes.html#review-of-day-4-sept-15-2017"><i class="fa fa-check"></i><b>2.1</b> Review of Day 4, Sept 15, 2017</a></li>
<li class="chapter" data-level="2.2" data-path="notes.html"><a href="notes.html#regression-and-interpretability"><i class="fa fa-check"></i><b>2.2</b> Regression and Interpretability</a></li>
<li class="chapter" data-level="2.3" data-path="notes.html"><a href="notes.html#toward-an-automated-regression-process"><i class="fa fa-check"></i><b>2.3</b> Toward an automated regression process</a></li>
<li class="chapter" data-level="2.4" data-path="notes.html"><a href="notes.html#selecting-model-terms"><i class="fa fa-check"></i><b>2.4</b> Selecting model terms</a></li>
<li class="chapter" data-level="2.5" data-path="notes.html"><a href="notes.html#programming-basics-graphics"><i class="fa fa-check"></i><b>2.5</b> Programming basics: Graphics</a></li>
<li class="chapter" data-level="2.6" data-path="notes.html"><a href="notes.html#in-class-programming-activity"><i class="fa fa-check"></i><b>2.6</b> In-class programming activity</a></li>
<li class="chapter" data-level="2.7" data-path="notes.html"><a href="notes.html#day-5-summary"><i class="fa fa-check"></i><b>2.7</b> Day 5 Summary</a><ul>
<li class="chapter" data-level="2.7.1" data-path="notes.html"><a href="notes.html#linear-regression"><i class="fa fa-check"></i><b>2.7.1</b> Linear regression</a></li>
<li class="chapter" data-level="2.7.2" data-path="notes.html"><a href="notes.html#coefficients-as-quantities"><i class="fa fa-check"></i><b>2.7.2</b> Coefficients as quantities</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="notes.html"><a href="notes.html#in-class-programming-activity-1"><i class="fa fa-check"></i><b>2.8</b> In-class programming activity</a></li>
<li class="chapter" data-level="2.9" data-path="notes.html"><a href="notes.html#day-6-summary"><i class="fa fa-check"></i><b>2.9</b> Day 6 Summary</a></li>
<li class="chapter" data-level="2.10" data-path="notes.html"><a href="notes.html#measuring-accuracy-of-the-model"><i class="fa fa-check"></i><b>2.10</b> Measuring Accuracy of the Model</a></li>
<li class="chapter" data-level="2.11" data-path="notes.html"><a href="notes.html#bias-of-the-model"><i class="fa fa-check"></i><b>2.11</b> Bias of the model</a><ul>
<li class="chapter" data-level="2.11.1" data-path="notes.html"><a href="notes.html#theory-of-whole-model-anova."><i class="fa fa-check"></i><b>2.11.1</b> Theory of whole-model ANOVA.</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="notes.html"><a href="notes.html#forward-backward-and-mixed-selection"><i class="fa fa-check"></i><b>2.12</b> Forward, backward and mixed selection</a></li>
<li class="chapter" data-level="2.13" data-path="notes.html"><a href="notes.html#programming-basics-functions"><i class="fa fa-check"></i><b>2.13</b> Programming Basics: Functions</a></li>
<li class="chapter" data-level="2.14" data-path="notes.html"><a href="notes.html#in-class-programming-activity-2"><i class="fa fa-check"></i><b>2.14</b> In-class programming activity</a></li>
<li class="chapter" data-level="2.15" data-path="notes.html"><a href="notes.html#review-of-day-7"><i class="fa fa-check"></i><b>2.15</b> Review of Day 7</a></li>
<li class="chapter" data-level="2.16" data-path="notes.html"><a href="notes.html#using-predict-to-calculate-precision"><i class="fa fa-check"></i><b>2.16</b> Using predict() to calculate precision</a></li>
<li class="chapter" data-level="2.17" data-path="notes.html"><a href="notes.html#conclusion"><i class="fa fa-check"></i><b>2.17</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html"><i class="fa fa-check"></i><b>3</b> Foundations: linear algebra, likelihood and Bayes’ rule</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#linear-algebra"><i class="fa fa-check"></i><b>3.1</b> Linear Algebra</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#arithmetic-of-linear-algebra-operations"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of linear algebra operations</a></li>
<li class="chapter" data-level="3.3" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#the-geometry-of-fitting"><i class="fa fa-check"></i><b>3.3</b> The geometry of fitting</a></li>
<li class="chapter" data-level="3.4" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#precision-of-the-coefficients"><i class="fa fa-check"></i><b>3.4</b> Precision of the coefficients</a></li>
<li class="chapter" data-level="3.5" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#likelihood-and-bayes"><i class="fa fa-check"></i><b>3.5</b> Likelihood and Bayes</a></li>
<li class="chapter" data-level="3.6" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#summary-of-day-8"><i class="fa fa-check"></i><b>3.6</b> Summary of Day 8</a></li>
<li class="chapter" data-level="3.7" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#day-9-announcements"><i class="fa fa-check"></i><b>3.7</b> Day 9 Announcements</a><ul>
<li class="chapter" data-level="3.7.1" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#whats-a-probability"><i class="fa fa-check"></i><b>3.7.1</b> What’s a probability?</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#conditional-probability"><i class="fa fa-check"></i><b>3.8</b> Conditional probability</a></li>
<li class="chapter" data-level="3.9" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#inverting-conditional-probabilities"><i class="fa fa-check"></i><b>3.9</b> Inverting conditional probabilities</a></li>
<li class="chapter" data-level="3.10" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#summary-of-day-9"><i class="fa fa-check"></i><b>3.10</b> Summary of Day 9</a></li>
<li class="chapter" data-level="3.11" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#likelihood-example"><i class="fa fa-check"></i><b>3.11</b> Likelihood example</a></li>
<li class="chapter" data-level="3.12" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#exponential-probability-density"><i class="fa fa-check"></i><b>3.12</b> Exponential probability density</a><ul>
<li class="chapter" data-level="3.12.1" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#meanwhile-further-north"><i class="fa fa-check"></i><b>3.12.1</b> Meanwhile, further north …</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#california-earthquake-warning-reprise"><i class="fa fa-check"></i><b>3.13</b> California earthquake warning, reprise</a></li>
<li class="chapter" data-level="3.14" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#the-price-is-right"><i class="fa fa-check"></i><b>3.14</b> The Price is Right!</a></li>
<li class="chapter" data-level="3.15" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#from-likelihood-to-bayes"><i class="fa fa-check"></i><b>3.15</b> From likelihood to Bayes</a></li>
<li class="chapter" data-level="3.16" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#choosing-models-using-maximum-likelihood"><i class="fa fa-check"></i><b>3.16</b> Choosing models using maximum likelihood</a></li>
<li class="chapter" data-level="3.17" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#day-9-review"><i class="fa fa-check"></i><b>3.17</b> Day 9 Review</a></li>
<li class="chapter" data-level="3.18" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#reading-what-is-bayesian-statistics"><i class="fa fa-check"></i><b>3.18</b> Reading: <em>What is Bayesian Statistics</em></a></li>
<li class="chapter" data-level="3.19" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#programming-basics-conditionals"><i class="fa fa-check"></i><b>3.19</b> Programming Basics: Conditionals</a></li>
<li class="chapter" data-level="3.20" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#ifelse-examples"><i class="fa fa-check"></i><b>3.20</b> <code>ifelse()</code> examples</a></li>
<li class="chapter" data-level="3.21" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#if-else-examples"><i class="fa fa-check"></i><b>3.21</b> if … else … examples</a></li>
<li class="chapter" data-level="3.22" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#simple"><i class="fa fa-check"></i><b>3.22</b> Simple</a></li>
<li class="chapter" data-level="3.23" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#blood-testing"><i class="fa fa-check"></i><b>3.23</b> Blood testing</a></li>
<li class="chapter" data-level="3.24" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#the-hyper-volume-of-the-hypersphere."><i class="fa fa-check"></i><b>3.24</b> The (hyper)-volume of the hypersphere.</a></li>
<li class="chapter" data-level="3.25" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#find-the-surface-area-d_n-rn-1."><i class="fa fa-check"></i><b>3.25</b> Find the surface area, <span class="math inline">\(D_n r^{n-1}\)</span>.</a></li>
<li class="chapter" data-level="3.26" data-path="foundations-linear-algebra-likelihood-and-bayes-rule.html"><a href="foundations-linear-algebra-likelihood-and-bayes-rule.html#in-class-programming-activity-3"><i class="fa fa-check"></i><b>3.26</b> In-class programming activity</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classifiers.html"><a href="classifiers.html"><i class="fa fa-check"></i><b>4</b> Classifiers</a><ul>
<li class="chapter" data-level="4.1" data-path="classifiers.html"><a href="classifiers.html#classification-overview"><i class="fa fa-check"></i><b>4.1</b> Classification overview</a></li>
<li class="chapter" data-level="4.2" data-path="classifiers.html"><a href="classifiers.html#day-10-preview"><i class="fa fa-check"></i><b>4.2</b> Day 10 preview</a></li>
<li class="chapter" data-level="4.3" data-path="classifiers.html"><a href="classifiers.html#probability-and-odds"><i class="fa fa-check"></i><b>4.3</b> Probability and odds</a></li>
<li class="chapter" data-level="4.4" data-path="classifiers.html"><a href="classifiers.html#log-odds"><i class="fa fa-check"></i><b>4.4</b> Log Odds</a></li>
<li class="chapter" data-level="4.5" data-path="classifiers.html"><a href="classifiers.html#why-use-odds"><i class="fa fa-check"></i><b>4.5</b> Why use odds?</a></li>
<li class="chapter" data-level="4.6" data-path="classifiers.html"><a href="classifiers.html#use-of-glm"><i class="fa fa-check"></i><b>4.6</b> Use of glm()</a></li>
<li class="chapter" data-level="4.7" data-path="classifiers.html"><a href="classifiers.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>4.7</b> Interpretation of coefficients</a></li>
<li class="chapter" data-level="4.8" data-path="classifiers.html"><a href="classifiers.html#example-logistic-regression-of-default"><i class="fa fa-check"></i><b>4.8</b> Example: Logistic regression of default</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html"><i class="fa fa-check"></i><b>5</b> Linear and Quadratic Discriminant Analysis</a><ul>
<li class="chapter" data-level="5.1" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#example-default-on-student-loans"><i class="fa fa-check"></i><b>5.1</b> Example: Default on student loans</a></li>
<li class="chapter" data-level="5.2" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#a-bayes-rule-approach"><i class="fa fa-check"></i><b>5.2</b> A Bayes’ Rule approach</a></li>
<li class="chapter" data-level="5.3" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#univariate-gaussian"><i class="fa fa-check"></i><b>5.3</b> Univariate Gaussian</a></li>
<li class="chapter" data-level="5.4" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#uncorrelated-bivariate-gaussian"><i class="fa fa-check"></i><b>5.4</b> Uncorrelated bivariate gaussian</a></li>
<li class="chapter" data-level="5.5" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#bivariate-normal-distribution-with-correlations"><i class="fa fa-check"></i><b>5.5</b> Bivariate normal distribution with correlations</a></li>
<li class="chapter" data-level="5.6" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#shape-of-multivariate-gaussian"><i class="fa fa-check"></i><b>5.6</b> Shape of multivariate gaussian</a></li>
<li class="chapter" data-level="5.7" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#generating-bivariate-normal-from-independent"><i class="fa fa-check"></i><b>5.7</b> Generating bivariate normal from independent</a></li>
<li class="chapter" data-level="5.8" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#independent-variables-x_i"><i class="fa fa-check"></i><b>5.8</b> Independent variables <span class="math inline">\(x_i\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#re-explaining-boldsymbolsigma"><i class="fa fa-check"></i><b>5.9</b> Re-explaining <span class="math inline">\(\boldsymbol\Sigma\)</span></a></li>
<li class="chapter" data-level="5.10" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#lda"><i class="fa fa-check"></i><b>5.10</b> LDA</a></li>
<li class="chapter" data-level="5.11" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#qda"><i class="fa fa-check"></i><b>5.11</b> QDA</a></li>
<li class="chapter" data-level="5.12" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#error-test-rates-on-various-classifiers"><i class="fa fa-check"></i><b>5.12</b> Error test rates on various classifiers</a></li>
<li class="chapter" data-level="5.13" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#error-rates"><i class="fa fa-check"></i><b>5.13</b> Error rates</a></li>
<li class="chapter" data-level="5.14" data-path="linear-and-quadratic-discriminant-analysis.html"><a href="linear-and-quadratic-discriminant-analysis.html#receiver-operating-curves"><i class="fa fa-check"></i><b>5.14</b> Receiver operating curves</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html"><i class="fa fa-check"></i><b>6</b> Cross-Validation and Bootstrapping</a><ul>
<li class="chapter" data-level="6.1" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#philosophical-approaches"><i class="fa fa-check"></i><b>6.1</b> Philosophical approaches</a><ul>
<li class="chapter" data-level="6.1.1" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#occams-razor-a-heuristic"><i class="fa fa-check"></i><b>6.1.1</b> Occam’s Razor: A heuristic</a></li>
<li class="chapter" data-level="6.1.2" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#einsteins-proverb"><i class="fa fa-check"></i><b>6.1.2</b> Einstein’s proverb</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#operationalizing-model-choice"><i class="fa fa-check"></i><b>6.2</b> Operationalizing model choice</a></li>
<li class="chapter" data-level="6.3" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#some-definitions-of-better"><i class="fa fa-check"></i><b>6.3</b> Some definitions of “better”</a></li>
<li class="chapter" data-level="6.4" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#training-and-testing"><i class="fa fa-check"></i><b>6.4</b> Training and Testing</a></li>
<li class="chapter" data-level="6.5" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#trade-off"><i class="fa fa-check"></i><b>6.5</b> Trade-off</a></li>
<li class="chapter" data-level="6.6" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#classical-theory-interlude"><i class="fa fa-check"></i><b>6.6</b> Classical theory interlude</a></li>
<li class="chapter" data-level="6.7" data-path="cross-validation-and-bootstrapping.html"><a href="cross-validation-and-bootstrapping.html#bootstrapping"><i class="fa fa-check"></i><b>6.7</b> Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html"><i class="fa fa-check"></i><b>7</b> Regularization, shrinkage and dimension reduction</a><ul>
<li class="chapter" data-level="7.1" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#best-subset-selection"><i class="fa fa-check"></i><b>7.1</b> Best subset selection</a></li>
<li class="chapter" data-level="7.2" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#approximation-to-best-subset-selection"><i class="fa fa-check"></i><b>7.2</b> Approximation to best subset selection</a></li>
<li class="chapter" data-level="7.3" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#classical-theory-of-best-model-choice"><i class="fa fa-check"></i><b>7.3</b> Classical theory of best model choice</a></li>
<li class="chapter" data-level="7.4" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#optimization"><i class="fa fa-check"></i><b>7.4</b> Optimization</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#what-are-we-optimizing-over"><i class="fa fa-check"></i><b>7.4.1</b> What are we optimizing over?</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#shrinkage-methods"><i class="fa fa-check"></i><b>7.5</b> Shrinkage methods</a><ul>
<li class="chapter" data-level="7.5.1" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#ridge-regression"><i class="fa fa-check"></i><b>7.5.1</b> Ridge regression</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#lasso"><i class="fa fa-check"></i><b>7.6</b> LASSO</a></li>
<li class="chapter" data-level="7.7" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#review"><i class="fa fa-check"></i><b>7.7</b> Review</a></li>
<li class="chapter" data-level="7.8" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#multi-collinearity"><i class="fa fa-check"></i><b>7.8</b> Multi-collinearity</a></li>
<li class="chapter" data-level="7.9" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#creating-correlations"><i class="fa fa-check"></i><b>7.9</b> Creating correlations</a></li>
<li class="chapter" data-level="7.10" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#rank-1-matrices"><i class="fa fa-check"></i><b>7.10</b> Rank 1 Matrices</a></li>
<li class="chapter" data-level="7.11" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#idea-of-singular-values."><i class="fa fa-check"></i><b>7.11</b> Idea of singular values.</a></li>
<li class="chapter" data-level="7.12" data-path="regularization-shrinkage-and-dimension-reduction.html"><a href="regularization-shrinkage-and-dimension-reduction.html#dimension-reduction"><i class="fa fa-check"></i><b>7.12</b> Dimension reduction</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html"><i class="fa fa-check"></i><b>8</b> Nonlinearity in linear models</a><ul>
<li class="chapter" data-level="8.1" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#smoothers"><i class="fa fa-check"></i><b>8.1</b> Smoothers</a><ul>
<li class="chapter" data-level="8.1.1" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#ideas-of-smoothness"><i class="fa fa-check"></i><b>8.1.1</b> Ideas of smoothness</a></li>
<li class="chapter" data-level="8.1.2" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#polynomials"><i class="fa fa-check"></i><b>8.1.2</b> Polynomials</a></li>
<li class="chapter" data-level="8.1.3" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#the-model-matrix"><i class="fa fa-check"></i><b>8.1.3</b> The model matrix</a></li>
<li class="chapter" data-level="8.1.4" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#sigmoidal-functions"><i class="fa fa-check"></i><b>8.1.4</b> Sigmoidal Functions</a></li>
<li class="chapter" data-level="8.1.5" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#hat-functions"><i class="fa fa-check"></i><b>8.1.5</b> Hat functions</a></li>
<li class="chapter" data-level="8.1.6" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#fourier-analysis"><i class="fa fa-check"></i><b>8.1.6</b> Fourier analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#steps"><i class="fa fa-check"></i><b>8.2</b> Steps</a></li>
<li class="chapter" data-level="8.3" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#other-functions"><i class="fa fa-check"></i><b>8.3</b> Other functions</a></li>
<li class="chapter" data-level="8.4" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#holes-in-the-data"><i class="fa fa-check"></i><b>8.4</b> Holes in the data</a></li>
<li class="chapter" data-level="8.5" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#bootstrapping-1"><i class="fa fa-check"></i><b>8.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="8.6" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#normal-theory-confidence-bands"><i class="fa fa-check"></i><b>8.6</b> Normal theory confidence bands</a></li>
<li class="chapter" data-level="8.7" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#splines"><i class="fa fa-check"></i><b>8.7</b> Splines</a><ul>
<li class="chapter" data-level="8.7.1" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#b-splines"><i class="fa fa-check"></i><b>8.7.1</b> B-splines</a></li>
<li class="chapter" data-level="8.7.2" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#natural-splines"><i class="fa fa-check"></i><b>8.7.2</b> Natural splines</a></li>
<li class="chapter" data-level="8.7.3" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#smoothing-splines"><i class="fa fa-check"></i><b>8.7.3</b> Smoothing splines</a></li>
<li class="chapter" data-level="8.7.4" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#smoothers-in-k-dimensions"><i class="fa fa-check"></i><b>8.7.4</b> Smoothers in k dimensions</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="nonlinearity-in-linear-models.html"><a href="nonlinearity-in-linear-models.html#gams"><i class="fa fa-check"></i><b>8.8</b> GAMS</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="programming-activity.html"><a href="programming-activity.html"><i class="fa fa-check"></i><b>9</b> Programming Activity</a></li>
<li class="chapter" data-level="10" data-path="where-to-place-knots.html"><a href="where-to-place-knots.html"><i class="fa fa-check"></i><b>10</b> Where to place knots?</a></li>
<li class="chapter" data-level="11" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html"><i class="fa fa-check"></i><b>11</b> Trees for Regression and Classification</a><ul>
<li class="chapter" data-level="11.1" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#splitting-criteria-for-classification-trees"><i class="fa fa-check"></i><b>11.1</b> Splitting Criteria for Classification Trees</a></li>
<li class="chapter" data-level="11.2" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#variable-importance"><i class="fa fa-check"></i><b>11.2</b> Variable importance</a></li>
<li class="chapter" data-level="11.3" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#avoiding-overfitting"><i class="fa fa-check"></i><b>11.3</b> Avoiding overfitting</a></li>
<li class="chapter" data-level="11.4" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#pruning"><i class="fa fa-check"></i><b>11.4</b> Pruning</a></li>
<li class="chapter" data-level="11.5" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#averaging"><i class="fa fa-check"></i><b>11.5</b> Averaging</a></li>
<li class="chapter" data-level="11.6" data-path="trees-for-regression-and-classification.html"><a href="trees-for-regression-and-classification.html#shrinking-boosting"><i class="fa fa-check"></i><b>11.6</b> Shrinking (“Boosting”)</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html"><i class="fa fa-check"></i><b>12</b> Support Vector Classifiers</a><ul>
<li class="chapter" data-level="12.1" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#lines-planes-and-hyperplanes"><i class="fa fa-check"></i><b>12.1</b> Lines, planes, and hyperplanes</a><ul>
<li class="chapter" data-level="12.1.1" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#rescaling-x"><i class="fa fa-check"></i><b>12.1.1</b> Rescaling X</a></li>
<li class="chapter" data-level="12.1.2" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#impose-an-absolute-constraint"><i class="fa fa-check"></i><b>12.1.2</b> Impose an absolute constraint</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#optimizing-within-the-constraint"><i class="fa fa-check"></i><b>12.2</b> Optimizing within the constraint</a></li>
<li class="chapter" data-level="12.3" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#allowing-violations-of-the-boundary"><i class="fa fa-check"></i><b>12.3</b> Allowing violations of the boundary</a></li>
<li class="chapter" data-level="12.4" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#nonlinear-boundaries"><i class="fa fa-check"></i><b>12.4</b> Nonlinear Boundaries</a></li>
<li class="chapter" data-level="12.5" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#support-vector-machine"><i class="fa fa-check"></i><b>12.5</b> Support Vector Machine</a></li>
<li class="chapter" data-level="12.6" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#kernels"><i class="fa fa-check"></i><b>12.6</b> Kernels</a></li>
<li class="chapter" data-level="12.7" data-path="support-vector-classifiers.html"><a href="support-vector-classifiers.html#svm-versus-logistic-regression"><i class="fa fa-check"></i><b>12.7</b> SVM versus logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="programming-basics.html"><a href="programming-basics.html"><i class="fa fa-check"></i><b>13</b> Programming Basics</a><ul>
<li class="chapter" data-level="13.1" data-path="programming-basics.html"><a href="programming-basics.html#programming-basics-i-names-classes-and-objects-progbasics1"><i class="fa fa-check"></i><b>13.1</b> Programming Basics I: Names, classes, and objects {progbasics1}</a><ul>
<li class="chapter" data-level="13.1.1" data-path="programming-basics.html"><a href="programming-basics.html#names"><i class="fa fa-check"></i><b>13.1.1</b> Names</a></li>
<li class="chapter" data-level="13.1.2" data-path="programming-basics.html"><a href="programming-basics.html#objects"><i class="fa fa-check"></i><b>13.1.2</b> Objects</a></li>
<li class="chapter" data-level="13.1.3" data-path="programming-basics.html"><a href="programming-basics.html#vectors"><i class="fa fa-check"></i><b>13.1.3</b> Vectors</a></li>
<li class="chapter" data-level="13.1.4" data-path="programming-basics.html"><a href="programming-basics.html#matrices"><i class="fa fa-check"></i><b>13.1.4</b> Matrices</a></li>
<li class="chapter" data-level="13.1.5" data-path="programming-basics.html"><a href="programming-basics.html#lists"><i class="fa fa-check"></i><b>13.1.5</b> Lists</a></li>
<li class="chapter" data-level="13.1.6" data-path="programming-basics.html"><a href="programming-basics.html#functions"><i class="fa fa-check"></i><b>13.1.6</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="programming-basics.html"><a href="programming-basics.html#programming-basics-linear-models"><i class="fa fa-check"></i><b>13.2</b> Programming basics: Linear Models</a><ul>
<li class="chapter" data-level="13.2.1" data-path="programming-basics.html"><a href="programming-basics.html#graphics-basics"><i class="fa fa-check"></i><b>13.2.1</b> Graphics basics</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="programming-basics.html"><a href="programming-basics.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>13.3</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="13.4" data-path="programming-basics.html"><a href="programming-basics.html#loopsiteration"><i class="fa fa-check"></i><b>13.4</b> Loops/Iteration</a></li>
<li class="chapter" data-level="13.5" data-path="programming-basics.html"><a href="programming-basics.html#parts-of-a-loop"><i class="fa fa-check"></i><b>13.5</b> Parts of a loop</a></li>
<li class="chapter" data-level="13.6" data-path="programming-basics.html"><a href="programming-basics.html#trivial-examples"><i class="fa fa-check"></i><b>13.6</b> Trivial examples</a></li>
<li class="chapter" data-level="13.7" data-path="programming-basics.html"><a href="programming-basics.html#bootstrapping-2"><i class="fa fa-check"></i><b>13.7</b> Bootstrapping</a></li>
<li class="chapter" data-level="13.8" data-path="programming-basics.html"><a href="programming-basics.html#leave-one-out-cross-validation."><i class="fa fa-check"></i><b>13.8</b> Leave-one-out cross-validation.</a></li>
<li class="chapter" data-level="13.9" data-path="programming-basics.html"><a href="programming-basics.html#building-a-package"><i class="fa fa-check"></i><b>13.9</b> Building a package</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i>Appendices</a></li>
<li class="chapter" data-level="" data-path="connecting-rstudio-to-your-github-repository.html"><a href="connecting-rstudio-to-your-github-repository.html"><i class="fa fa-check"></i>Connecting RStudio to your GitHub repository</a><ul>
<li class="chapter" data-level="13.10" data-path="connecting-rstudio-to-your-github-repository.html"><a href="connecting-rstudio-to-your-github-repository.html#setting-up-rstudio"><i class="fa fa-check"></i><b>13.10</b> Setting up RStudio</a></li>
<li class="chapter" data-level="13.11" data-path="connecting-rstudio-to-your-github-repository.html"><a href="connecting-rstudio-to-your-github-repository.html#setting-up-your-math-253-repository"><i class="fa fa-check"></i><b>13.11</b> Setting up your Math 253 repository</a></li>
<li class="chapter" data-level="13.12" data-path="connecting-rstudio-to-your-github-repository.html"><a href="connecting-rstudio-to-your-github-repository.html#using-your-repository"><i class="fa fa-check"></i><b>13.12</b> Using your repository</a></li>
<li class="chapter" data-level="13.13" data-path="connecting-rstudio-to-your-github-repository.html"><a href="connecting-rstudio-to-your-github-repository.html#why-are-we-doing-this"><i class="fa fa-check"></i><b>13.13</b> Why are we doing this?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="instructions-for-the-publishing-system-bookdown.html"><a href="instructions-for-the-publishing-system-bookdown.html"><i class="fa fa-check"></i>Instructions for the publishing system: Bookdown</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dtkaplan/math253" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for Statistical Computing &amp; Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="programming-basics" class="section level1">
<h1><span class="header-section-number">Topic 13</span> Programming Basics</h1>
<div id="programming-basics-i-names-classes-and-objects-progbasics1" class="section level2">
<h2><span class="header-section-number">13.1</span> Programming Basics I: Names, classes, and objects {progbasics1}</h2>
<div id="names" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Names</h3>
<p>Composed of letters, numbers, <code>_</code> and <code>.</code>.<br />
- Don’t use <code>.</code> — it’s a bad habit. But plenty of people do. - Can’t lead with a number. - Capitalization counts. - Unquoted (… almost always)</p>
</div>
<div id="objects" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Objects</h3>
<p>Information (bits) in a particular format.<br />
- Different formats for different purposes. - The format is the <code>class()</code> or <code>mode()</code>. <code>mode</code> is more basic than <code>class</code>.</p>
<p><strong>Assignment</strong>: Give a name to an object</p>
</div>
<div id="vectors" class="section level3">
<h3><span class="header-section-number">13.1.3</span> Vectors</h3>
<p>1-dimensional homogeneous collections of numbers, character strings, booleans/logicals, etc.</p>
<div id="must-know" class="section level4">
<h4><span class="header-section-number">13.1.3.1</span> Must Know!</h4>
<p>There are some basic types of vectors. The most common are:</p>
<ol style="list-style-type: decimal">
<li><strong>numeric</strong>, e.g. <code>3</code>, <code>3.14159</code>, <code>6.023e26</code>,<code>6.626196e-34</code></li>
<li><strong>character</strong>, e.g. <code>&quot;hello&quot;</code>, `“When in the course of human events …”</li>
<li><strong>logical</strong> (or “booleans”). The only allowable values: <code>TRUE</code> and <code>FALSE</code></li>
</ol>
<p>Much of the software you’ll use in this course will work with an alternative to character strings called “factors.”</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>factor</strong>, an encoded representation of levels of a categorical variable.</li>
</ol>
<p>Some operations you will use when dealing with categorical variables are <code>as.character()</code> and (for older software) <code>as.factor()</code>.</p>
<p>Vectors are “1-dimensional” collections. That is, you need only one index to refer to a specific element.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_vector &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;apple&quot;</span>, <span class="st">&quot;berry&quot;</span>, <span class="st">&quot;cherry&quot;</span>)
my_vector[<span class="dv">2</span>]</code></pre></div>
<pre><code>## [1] &quot;berry&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_vector[<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)]</code></pre></div>
<pre><code>## [1] &quot;cherry&quot; &quot;apple&quot;  &quot;berry&quot;  &quot;berry&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_vector[<span class="dv">4</span>] &lt;-<span class="st"> &quot;durian&quot;</span></code></pre></div>
<p>Boolean indexing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_vector[my_vector &gt;<span class="st"> &quot;b&quot;</span>]</code></pre></div>
<pre><code>## [1] &quot;berry&quot;  &quot;cherry&quot; &quot;durian&quot;</code></pre>
<p>If you want, you can convert the boolean style to a number style with <code>which()</code>.</p>
<p>Other important functions:</p>
<ul>
<li><code>length()</code>, to say how many elements there are in the vector. The length can be zero.</li>
<li>Arithmetic operations, e.g. <code>sum()</code>, <code>mean()</code>, <code>max()</code>, <code>cumsum()</code>, and other functions (e.g. <code>sqrt()</code>, <code>log()</code>, <code>sin()</code>), …</li>
<li>Logical operations, that is, operations that transform vectors into a logical vector. Examples:
<ul>
<li>Comparison: <code>&gt;</code>, <code>==</code>, <code>&gt;=</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code></li>
<li>Boolean operations: <code>!</code>, <code>|</code>, <code>&amp;</code>. (Note, these are single characters.)</li>
</ul></li>
<li>Categorical operations, e.g. <code>table()</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">funny &lt;-<span class="st"> </span><span class="kw">ceiling</span>(<span class="kw">length</span>(my_vector)*<span class="kw">runif</span>(<span class="dv">10</span>))
my_vector[funny]</code></pre></div>
<pre><code>##  [1] &quot;durian&quot; &quot;apple&quot;  &quot;apple&quot;  &quot;berry&quot;  &quot;berry&quot;  &quot;berry&quot;  &quot;durian&quot; &quot;apple&quot;  &quot;durian&quot; &quot;durian&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(my_vector)</code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(my_vector)</code></pre></div>
<pre><code>## NULL</code></pre>
</div>
</div>
<div id="matrices" class="section level3">
<h3><span class="header-section-number">13.1.4</span> Matrices</h3>
<ul>
<li>2-dimensional homogeneous collections of numbers or of character strings. These collections are called <em>matrices</em>
<ul>
<li>2-dimensional means you need two indices to refer to a specific element.</li>
<li><code>dim()</code></li>
<li>Operations, e.g., <code>t()</code>, <code>colSums()</code>, <code>rowSums()</code>, <code>%*%</code>, …</li>
<li>Index matrices with <code>[ , ]</code>. You need to give two</li>
</ul></li>
</ul>
</div>
<div id="lists" class="section level3">
<h3><span class="header-section-number">13.1.5</span> Lists</h3>
<p>1-dimensional heterogeneous collections</p>
<ul>
<li>create with <code>list()</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">magic =</span> <span class="dv">1</span>:<span class="dv">10</span>, <span class="dt">greeting =</span> <span class="st">&quot;hello&quot;</span>, <span class="dt">is_wednesday =</span> <span class="ot">FALSE</span>)
my_list[<span class="kw">c</span>(<span class="st">&quot;greeting&quot;</span>, <span class="st">&quot;magic&quot;</span>, <span class="st">&quot;magic&quot;</span>)]</code></pre></div>
<pre><code>## $greeting
## [1] &quot;hello&quot;
## 
## $magic
##  [1]  1  2  3  4  5  6  7  8  9 10
## 
## $magic
##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_list$magic</code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<ul>
<li>index with <code>[[ ]]</code> or <code>[ ]</code>. The first is for an individual item which you want in the form of that item itself. The second is to create a subset of the list which will be a list itself.</li>
<li><p>you can name items in lists and refer to them by name. <code>[[&quot;name&quot;]]</code> To set names of list items, use named arguments to <code>list()</code> or use the <code>names()</code> function on the left-hand side of the <code>&lt;-</code> operation. (The left-hand side of <code>&lt;-</code> is called an “assignable.” These can be names, but they can be other things as well such as indexed arrays, <code>names()</code>, etc.)</p></li>
<li><p>Data frames</p></li>
</ul>
<p>A list of vectors.</p>
<ul>
<li>Each component in a given vector must be the same kind of thing as the other components. (Special cases: <code>NA</code> for missing data. Two more special things for numerical data.<code>NaN</code>, &amp; <code>Inf</code>)</li>
<li>Important functions: <code>nrow()</code>, <code>names()</code>, <code>$</code>.</li>
</ul>
</div>
<div id="functions" class="section level3">
<h3><span class="header-section-number">13.1.6</span> Functions</h3>
<p>Take inputs and produce an output (and maybe a side-effect). - Make them with <code>function(){ }</code>, a special form. (It’s not actually a function!) - Try this</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(sin)
<span class="kw">class</span>(<span class="dv">3</span>)
<span class="kw">class</span>(<span class="st">&quot;a string&quot;</span>)
<span class="kw">class</span>(function)</code></pre></div>
<pre><code>## Error: &lt;text&gt;:4:15: unexpected &#39;)&#39;
## 3: class(&quot;a string&quot;)
## 4: class(function)
##                  ^</code></pre>
</div>
</div>
<div id="programming-basics-linear-models" class="section level2">
<h2><span class="header-section-number">13.2</span> Programming basics: Linear Models</h2>
<p>Syntactic element: <strong>formulas</strong>. Formulas provide a way of using variables “symbolically.” This is useful, for instance, in depicting the desired relationship among variables. Two forms:</p>
<ul>
<li><code>y ~ x</code> two-sided</li>
<li><code>~ x</code> one-sided</li>
<li>NOT ALLOWED, <code>y ~</code></li>
</ul>
<p>Important functions:</p>
<ul>
<li><code>lm()</code>, <code>predict()</code> , <code>anova()</code>, <code>summary()</code>.</li>
<li>For later: <code>solve()</code>, <code>model.matrix()</code>.</li>
<li>From 155: <code>coef()</code>, <code>fitted()</code>, <code>resid()</code></li>
</ul>
<p>Training with <code>lm()</code>: Specify formula <code>Y ~ X1 + X2</code> …</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(College, <span class="dt">package =</span> <span class="st">&quot;ISLR&quot;</span>)
mod &lt;-<span class="st"> </span><span class="kw">lm</span>(Outstate ~<span class="st"> </span>Enroll +<span class="st"> </span>Accept +<span class="st"> </span>perc.alumni, <span class="dt">data =</span> College ) 
<span class="kw">coef</span>(mod)</code></pre></div>
<pre><code>## (Intercept)      Enroll      Accept perc.alumni 
## 6387.368606   -2.888077    1.101019  179.528731</code></pre>
<p>What kind of thing is <code>mod</code>?</p>
<p>Model output with <code>predict()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(mod, 
        <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Enroll =</span> <span class="dv">100</span>, <span class="dt">Accept =</span> <span class="dv">1000</span>, <span class="dt">perc.alumni =</span> <span class="dv">25</span>))</code></pre></div>
<pre><code>##       1 
## 11687.8</code></pre>
<p>What kind of thing is the output of <code>predict()</code>?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(mod, <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>,
        <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Enroll =</span> <span class="dv">100</span>, <span class="dt">Accept =</span> <span class="dv">1000</span>, <span class="dt">perc.alumni =</span> <span class="dv">25</span>))</code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 11687.8 11383.57 11992.03</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(mod, <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>,
        <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">Enroll =</span> <span class="dv">100</span>, <span class="dt">Accept =</span> <span class="dv">1000</span>, <span class="dt">perc.alumni =</span> <span class="dv">25</span>))</code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 11687.8 5548.956 17826.64</code></pre>
<p>Why is the “confidence interval” so much narrower than the “prediction interval?”</p>
<p><strong>Inference</strong> with <code>anova()</code> and <code>summary()</code>. This is all “in-sample” inference, not cross-validated.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">M &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="st"> </span>Enroll +<span class="st"> </span>Accept *<span class="st"> </span>perc.alumni, <span class="dt">data =</span> College)
<span class="kw">qr.solve</span>(M, College$Outstate)</code></pre></div>
<pre><code>##        (Intercept)             Enroll             Accept        perc.alumni Accept:perc.alumni 
##      7024.34843865        -3.00377409         0.78401053       147.31268325         0.02011475</code></pre>
<p>For the people who have had linear algebra, why doesn’t this work?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">solve</span>(M, College$Outstate)</code></pre></div>
<pre><code>## Error in solve.default(M, College$Outstate): &#39;a&#39; (777 x 5) must be square</code></pre>
<p><a href="../ProgrammingActivities/Day-03-Programming.html">Indexing on data: training and testing data sets</a></p>
<div id="graphics-basics" class="section level3">
<h3><span class="header-section-number">13.2.1</span> Graphics basics</h3>
<ol style="list-style-type: decimal">
<li>API for graphics: <code>plot()</code>, <code>points()</code>, <code>lines()</code>, <code>polygon()</code>, <code>text()</code>, …</li>
</ol>
</div>
</div>
<div id="k-nearest-neighbors" class="section level2">
<h2><span class="header-section-number">13.3</span> K-nearest neighbors</h2>
<p>K-nearest neighbors is a simple, general kind of function-building method. But some problems:</p>
<ul>
<li>Interpretability: but you can always take partial derivatives.</li>
<li>When you have prediction (aka “explanatory”) variables in dollars and in miles, how do you calculate the distance between points? What are the dimensions of distance?
<ul>
<li>Dimensionality refers to the physical feature, e.g. time, distance, area, volume, money, charge, luminance, mass, …</li>
<li>Units are the ways in which dimensions are measured, e.g., cups, gallons, liters … all refer to volume
<ul>
<li>Give some examples of units for each of the dimensions.</li>
<li>Some everyday quantities are dimensionless, e.g. pure numbers. Give some examples: … (angles, percent, fractions, … but not ratios in general.)</li>
</ul></li>
<li>Regression fixes units automatically, since the coefficients themselves have dimensionality. They will adjust automatically to changes in units, so the model is the same regardless of whether we use miles, km, parsecs, …</li>
<li>In KNN, to avoid dependence on units, need to do some standardization by dividing by something in the same units, e.g. sd.</li>
</ul></li>
<li>Curse of dimensionality. Let’s create 1000 randomly placed points in the unit square:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpts &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">runif</span>(<span class="dv">2</span>*<span class="dv">1000</span>), <span class="dt">ncol=</span><span class="dv">2</span>)</code></pre></div>
<p>What’s the distribution of distances from a single random point to the 1000 others:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">our_point &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">2</span>)</code></pre></div>
<p>The distance between our point and each of the others</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tmp &lt;-<span class="st"> </span><span class="kw">matrix</span>(our_point, <span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">nrow=</span><span class="dv">1000</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)
delta &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">rowSums</span>((rpts -<span class="st"> </span>tmp)^<span class="dv">2</span>))</code></pre></div>
<ul>
<li>How far away is a typical point?</li>
<li>Write a function that takes the matrix of points and the “our point” and finds the distance from our point to each and every one of the points in the matrix.</li>
<li>How far away is a typical point in 1-dimensional space?</li>
<li>In 10-dimensional space?</li>
<li>In 100-dimensional space?</li>
</ul>
</div>
<div id="loopsiteration" class="section level2">
<h2><span class="header-section-number">13.4</span> Loops/Iteration</h2>
<p>Loops are the programming control structure that allows you to repeat the same commands many times.</p>
<p><em>A definition of insanity</em>: Doing something over and over again and expecting a different result.</p>
</div>
<div id="parts-of-a-loop" class="section level2">
<h2><span class="header-section-number">13.5</span> Parts of a loop</h2>
<ol style="list-style-type: decimal">
<li><p>Preparation — creating a place to hold the results</p>
<p>This is called the “accumulator.”</p></li>
<li>Identify a set to loop over.</li>
<li>Inside the loop, modify the accumulator</li>
<li><p>When the loop is done, package up the results.</p></li>
</ol>
</div>
<div id="trivial-examples" class="section level2">
<h2><span class="header-section-number">13.6</span> Trivial examples</h2>
<ul>
<li>Find the sum of squares of a vector. (R <code>sum(x^2)</code>)</li>
<li>Find the biggest element of a vector. (R <code>max()</code>)</li>
<li>Generate <span class="math inline">\(k\)</span> random numbers from the set <code>1:n</code> (R <code>sample()</code>)
<ul>
<li>with replacement: pre-allocate result, loop and select</li>
<li>without replacement: shrink the set of possibilities each time.</li>
</ul></li>
<li>Find the <span class="math inline">\(k\)</span>th Fibonacci number:
<ul>
<li>with <code>previous</code> and <code>before_that</code> as the state</li>
<li>with an array as the state: initialize to <code>c(1, 1)</code></li>
<li>with a global array as the state memoization.</li>
<li>with an array created in the capturing environment.</li>
</ul></li>
</ul>
<p>**In practice, we would use the already parallelized R functions. See also <code>Vectorize()</code>.</p>
</div>
<div id="bootstrapping-2" class="section level2">
<h2><span class="header-section-number">13.7</span> Bootstrapping</h2>
<p>Process</p>
<ul>
<li>Set up accumulator — what should we store? (all coefs)</li>
<li>but we don’t know what this should look like until we’ve tried it out</li>
<li>Loop:</li>
<li>create a new random sample</li>
<li>fit the model</li>
<li>store away the results</li>
<li>Post-process:</li>
<li>Give std-err?</li>
<li>Give covariance matrix?</li>
<li>Give array?</li>
</ul>
</div>
<div id="leave-one-out-cross-validation." class="section level2">
<h2><span class="header-section-number">13.8</span> Leave-one-out cross-validation.</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># preparation</span>
my_data &lt;-<span class="st"> </span>mosaicData::KidsFeet
error &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(my_data))

<span class="co"># The looping set: each row in my_data</span>
for (k in <span class="dv">1</span>:<span class="kw">nrow</span>(my_data)) {
  <span class="co"># the body of the loop</span>
  mod &lt;-<span class="st"> </span><span class="kw">lm</span>(width ~<span class="st"> </span>length *<span class="st"> </span>sex, <span class="dt">data =</span> my_data[ -k, ])
  mod_value &lt;-<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> my_data[k, ])
  error[k] &lt;-<span class="st"> </span>my_data$width[k] -<span class="st"> </span>mod_value
}

<span class="co"># packaging up the results</span>
result &lt;-<span class="st"> </span><span class="kw">sum</span>(error^<span class="dv">2</span>)</code></pre></div>
<p>Look at the result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result</code></pre></div>
<pre><code>## [1] 6.304381</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regular_model &lt;-<span class="st"> </span><span class="kw">lm</span>(width ~<span class="st"> </span>length *<span class="st"> </span>sex, <span class="dt">data =</span> my_data)
<span class="kw">sum</span>(<span class="kw">resid</span>(regular_model)^<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 5.329327</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(regular_model)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: width
##            Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## length      1 4.0557  4.0557 26.6353 9.86e-06 ***
## sex         1 0.4790  0.4790  3.1456  0.08484 .  
## length:sex  1 0.0037  0.0037  0.0246  0.87638    
## Residuals  35 5.3293  0.1523                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>In ANOVA, we use a degrees of freedom to adjust for the under-estimate of residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">resid</span>(regular_model)^<span class="dv">2</span>) /<span class="st"> </span><span class="dv">35</span></code></pre></div>
<pre><code>## [1] 0.1522665</code></pre>
<p>In leave-one-out, we can simply average the errors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result /<span class="st"> </span><span class="dv">38</span></code></pre></div>
<pre><code>## [1] 0.1659048</code></pre>
</div>
<div id="building-a-package" class="section level2">
<h2><span class="header-section-number">13.9</span> Building a package</h2>
<p>Divide up into groups of two or three.</p>
<ol style="list-style-type: decimal">
<li>Open a new project: choose “new directory”, “choose R package”</li>
<li>Go to the “Build” tab, select More/Configure Build Tools and fill in the checkmark for Roxygen comments.</li>
<li>Write functions for <span class="math inline">\(C_p\)</span>, <span class="math inline">\(AIC\)</span>, <span class="math inline">\(BIC\)</span>, and adjusted <span class="math inline">\(R^2\)</span>. The function should take a model as input.</li>
<li>Document the functions.</li>
<li>Compile the package.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="support-vector-classifiers.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendices.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dtkaplan/math253/edit/master/850-Programming.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
